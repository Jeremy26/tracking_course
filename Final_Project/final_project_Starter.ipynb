{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project_Starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Zy5R377k8C",
        "colab_type": "text"
      },
      "source": [
        "# Welcome to the Final Project!\n",
        "\n",
        "Course: https://jeremycohen.podia.com/tracking-obstacles-using-computer-vision\n",
        "\n",
        "In this project, you will learn to associate bounding boxes on multiple frames using the Hungarian Algorithm!\n",
        "\n",
        "\n",
        "You will work on 3 aspects of the **multi-object tracker**:\n",
        "\n",
        "*   Use YOLO and launch an object detection algorithm\n",
        "*   Use The Hungarian Algorithm and associate the boxes\n",
        "*   Improve the algorithm to avoid false positives and false negatives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbG8vs9u8OOg",
        "colab_type": "text"
      },
      "source": [
        "This is a part included to link your Google Colab file (.ipynb) to your Google Drive folder.\n",
        "\n",
        "If you don't work on Colab, you won't need these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPW9hbcuYxqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/yourpathhere\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcNCkytu3ykt",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Detection\n",
        "\n",
        "In order to make multi-object tracking work, we will need to do a detection step. The tracking will heavily rely on the detector, it better be good.\n",
        "\n",
        "We will choose the [YOLO algorithm](https://pjreddie.com/darknet/yolo/) that is both accurate and fast.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1446/1*YpNE9OQeshABhBgjyEXlLA.png\" width=\"500\">\n",
        "\n",
        "\n",
        "Eventually, we want bounding box detection\n",
        "\n",
        "<img src=\"https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UStSXSC3RKue",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries and Test Images\n",
        "\n",
        "Let's import the libraries and test images.<p>\n",
        "I took a video and wrote a short script to take a picture every 7 frame of the image. Instead of working at **60 FPS** (recording frame rate), consider you have an algorithm working at 60/7 or about **9 frame per second**.<p>_\n",
        "\n",
        "**Why the cut ?**<p>\n",
        "YOLO is very fast, it can work at 60 FPS.\n",
        "For tracking to be a bit challenging, let's not have 99% IOU every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n24pesxqdTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Imports\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import pickle\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ6bw_4Rqh3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Load the Images\n",
        "dataset_images = pickle.load(open('Images/images_tracking.p', \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duVgFEYHfRsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_images(input_images):\n",
        "    fig=plt.figure(figsize=(100,100))\n",
        "\n",
        "    for i in range(len(input_images)):\n",
        "        fig.add_subplot(1, len(input_images), i+1)\n",
        "        plt.imshow(input_images[i])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ref3X-llqt4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_images(dataset_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P5YlyD3UZmq",
        "colab_type": "text"
      },
      "source": [
        "## Run Initial Obstacle Detection - Modify the YOLO file\n",
        "\n",
        "We will need to modify the original yolo.py file. Go to this file, **duplicate it**, and **modify the duplicate online** using Google Drive's text editor. <p>_\n",
        "\n",
        "**What modifications should you do?**<p>\n",
        "The current *inference()* function outputs an image.\n",
        "To work with the hungarian algorithm, we will need the bounding box.<p>\n",
        "* **Modify the postprocess()** function as well as the **inference() function** to **return the bounding box**.\n",
        "* Then, we will only work with the original image and the bounding boxes\n",
        "* Call the new file **yolo_modified.py**\n",
        " and import it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2QETWZhM3j8",
        "colab_type": "code",
        "outputId": "944ed367-e510-43e4-dbec-aee8b30a6bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Run obstacle detection for the images\n",
        "from yolo_for_tracking import *\n",
        "\n",
        "## RUN OBSTACLE DETECTION ON EACH IMAGE; STORE THE RESULTS IN A LIST OF IMAGES, AND A LIST OF BOXES\n",
        "## YOUR CODE HERE\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHvtTDrEVr_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the results and the detected boxes\n",
        "\n",
        "## YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUIbq5XkXGaY",
        "colab_type": "text"
      },
      "source": [
        "## One Obstacle - One Color\n",
        "**Last Step!** <p>\n",
        "We now one one color per bounding box! All cars in blue is useless! <p>\n",
        "We will create an Obstacle class that we will modify.\n",
        "Each detected obstacle should have:\n",
        "* an id\n",
        "* a current bounding box\n",
        "* a previous bounding box<p>_\n",
        "\n",
        "**In the end, we will draw a bounding box based on the id.** <p>\n",
        "If the id changes, the color will change also."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a99w3HIF1MLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Obstacle():\n",
        "    def __init__(self, idx, box):\n",
        "        \"\"\"\n",
        "        Init function. The obstacle must have an id and a box.\n",
        "        \"\"\"\n",
        "        self.idx = idx\n",
        "        self.box = box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ly04QA_gOMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def id_to_color(idx):\n",
        "    \"\"\"\n",
        "    Random function to convert an id to a color\n",
        "    Do what you want here but keep numbers below 255\n",
        "    \"\"\"\n",
        "    blue = idx*5 % 256\n",
        "    green = idx*36 %256\n",
        "    red = idx*23 %256\n",
        "    return (red, green, blue)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWacVf_5gShC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function.\n",
        "    You already ran the detector on all 9 images. The variable is result_boxes.\n",
        "    Use this to assign an id and draw a rectangle based on the id.\n",
        "    \"\"\"\n",
        "    ## YOUR CODE HERE\n",
        "    pass\n",
        "\n",
        "result_images_2 = main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Eq18R7WYXkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Print the results\n",
        "visualize_images(result_images_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmsuPGWAbHvd",
        "colab_type": "text"
      },
      "source": [
        "We did it!<p>...<p>\n",
        "\n",
        "But as you can see, the colors are not kept along the images. **We don't have active tracking yet**!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCEQikXa30Cx",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Association\n",
        "\n",
        "We now have a detection algorithm working! Congratulations!\n",
        "The next step is to **match the detections** from one frame to another and **keep the color along the 9 images**.<p>\n",
        "It should be dynamic and **work no matter the number of images**. In the end, we'll apply **this algorithm on a video**.\n",
        "\n",
        "Eventually, we'll want a good association system\n",
        "\n",
        "![Texte alternatifâ€¦](https://miro.medium.com/proxy/0*yN9MllhmuglJORss.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD-ZE43rcVvW",
        "colab_type": "text"
      },
      "source": [
        "## Metrics\n",
        "\n",
        "The first thing we'll need is to define a metric!\n",
        "\n",
        "* If you **don't want a big challenge**, the **IOU cost** will do just fine!\n",
        "* If you want a **medium challenge**, you can try to **implement [this paper](https://arxiv.org/pdf/1709.03572.pdf)**. Read carefully page 19-20 and try to implement these costs with IOU. It will filter out incoherent boxes.\n",
        "* If you want the **biggest challenge**, try to **code [Deep SORT](https://arxiv.org/pdf/1703.07402.pdf)** and associate Deep Convolutional features to it. <p>\n",
        "\n",
        "In the end, you should have a **single number in the cost matrix**. And it should be representative of the cost, like IOU is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-grOk3_hHSc",
        "colab_type": "text"
      },
      "source": [
        "### IOU COST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NpEcw8L5HnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_data(box):\n",
        "    \"\"\"\n",
        "    Convert data from (x1,y1, w, h) to (x1,y1,x2,y2)\n",
        "    \"\"\"\n",
        "    x1 = box[0]\n",
        "    x2 = box[0] + box[2]\n",
        "    y1 = box[1]\n",
        "    y2 = box[1]+box[3]\n",
        "    return x1,y1,x2,y2\n",
        "\n",
        "def box_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Computer Intersection Over Union cost\n",
        "    \"\"\"\n",
        "    box1 = convert_data(box1)\n",
        "    box2 = convert_data(box2)\n",
        "    xA = max(box1[0], box2[0])\n",
        "    yA = max(box1[1], box2[1])\n",
        "    xB = min(box1[2], box2[2])\n",
        "    yB = min(box1[3], box2[3])\n",
        "\n",
        "    inter_area = max(0, xB - xA + 1) * max(0, yB - yA + 1) #abs((xi2 - xi1)*(yi2 - yi1))\n",
        "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1) #abs((box1[3] - box1[1])*(box1[2]- box1[0]))\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1) #abs((box2[3] - box2[1])*(box2[2]- box2[0]))\n",
        "    union_area = (box1_area + box2_area) - inter_area\n",
        "    # compute the IoU\n",
        "    iou = inter_area/float(union_area)\n",
        "    return iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRVXGejWhL_S",
        "colab_type": "text"
      },
      "source": [
        "### Exponential, Linear, And IOU Costs\n",
        "\n",
        "Use this paper to code the solution: https://arxiv.org/pdf/1709.03572.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK7LfLBthi8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CREATE A FUNCTION HUNGARIAN_COST THAT OUTPUTS THE HUNGARIAN COST AS IN THE PAPER\n",
        "## BE CAREFUL NOT TO DIVIDE BY ZERO\n",
        "\n",
        "## YOUR CODE HERE\n",
        "def hungarian_cost():\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6CvRBXgjWK2",
        "colab_type": "text"
      },
      "source": [
        "## The Hungarian Algorithm\n",
        "We can now use the previous code from the workshop to track bounding boxes!\n",
        "\n",
        "* Create an **associate()** function that takes **two lists of boxes** (time t-1 and time t) and that outputs **the matches, the new detections, and the unmatched tracks**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXwhIsjd6kFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def associate(old_boxes, new_boxes):\n",
        "    \"\"\"\n",
        "    old_boxes will represent the former bounding boxes (at time 0)\n",
        "    new_boxes will represent the new bounding boxes (at time 1)\n",
        "    Function goal: Define a Hungarian Matrix with IOU as a metric and return, for each box, an id\n",
        "    RETURN: Matches, Unmatched Detections, Unmatched Trackers\n",
        "    \"\"\"\n",
        "    ## YOUR CODE HERE\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_TtyGCW5hvW",
        "colab_type": "text"
      },
      "source": [
        "## Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4uClkOsM7Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(input_image):\n",
        "    \"\"\"\n",
        "    Receives an images\n",
        "    Outputs the result image, and a list of obstacle objects \n",
        "    \"\"\"\n",
        "    ## YOUR CODE HERE\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cVeLR137YGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Call the main loop\n",
        "\n",
        "yolo = YOLO()\n",
        "idx = 0\n",
        "\n",
        "fig=plt.figure(figsize=(100,100))\n",
        "\n",
        "result_images_3 = copy.deepcopy(dataset_images)\n",
        "\n",
        "out_imgs = []\n",
        "\n",
        "for i in range(len(result_images_3)):\n",
        "    out_img, stored_obstacles = main(result_images_3[i])\n",
        "    out_imgs.append(out_img)\n",
        "    fig.add_subplot(1, len(result_images_3), i+1)\n",
        "    plt.imshow(out_imgs[i])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftb6lKOSBJup",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Improvement (optional)\n",
        "\n",
        "We now have a pretty good tracker! <p>\n",
        "One thing that is not very good is that it relies solely on the detector.\n",
        "If we miss the detection, we miss everything. <p>\n",
        "\n",
        "In this part, we'll introduce two ideas:\n",
        "* False Positive\n",
        "* False Negative<p>\n",
        "\n",
        "A **false positive** means that you detected an obstacle that shouldn't detect.<p>\n",
        "We'll solve it by introducing a **MIN_HIT_STREAK** variable. If the detector detects something once, it is not displayed. If it **detects it twice in a row**, or 3 times in a row (thanks to matching), it is displayed.\n",
        "\n",
        "A **false negative** means that you didn't detect an obstacle that should have been detected.<p>\n",
        "We'll solve it by introducing a **MAX_AGE** variable. If an obstacle is suddently unmatched, we **keep displaying** it. If it is unmatched again, or more times, we remove it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLcyXVrBgeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_HIT_STREAK = ## YOUR CODE HERE\n",
        "MAX_UNMATCHED_AGE = ## YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeBeNMRWQHG8",
        "colab_type": "text"
      },
      "source": [
        "**Obstacle Class** <p>\n",
        "Let's redefine the Obstacle class to include these values\n",
        "Every obstacle should have:\n",
        "* an id\n",
        "* a box\n",
        "* an age (number of times matched)\n",
        "* an unmatched frame number (number of times unmatched)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUG4St3QDTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Obstacle():\n",
        "    def __init__(self, idx, box, age=1, unmatched_age=0):\n",
        "        self.idx = idx\n",
        "        self.box = box\n",
        "        ## ADD AGE AND UNMATCHED AGE\n",
        "        ## YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNK1OJVWQj3G",
        "colab_type": "text"
      },
      "source": [
        "**Main Loop**<p>\n",
        "Now we can redefine the main loop\n",
        "We simply add conditions to display or not an obstacle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5UU7mgTQjR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(input_image):\n",
        "    \"\"\"\n",
        "    Receives an images\n",
        "    Outputs the result image, and a list of obstacle objects \n",
        "    \"\"\"\n",
        "    ## MODIFY THE MAIN FUNCTION TO NOW CONSIDER AGE AND UNMATCHED AGE\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE45f0_JQdGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yolo = YOLO()\n",
        "idx = 0\n",
        "\n",
        "fig=plt.figure(figsize=(100,100))\n",
        "\n",
        "result_images_3 = copy.deepcopy(dataset_images)\n",
        "\n",
        "out_imgs = []\n",
        "\n",
        "for i in range(len(result_images_3)):\n",
        "    out_img = main(result_images_3[i])\n",
        "    out_imgs.append(out_img)\n",
        "    fig.add_subplot(1, len(result_images_3), i+1)\n",
        "    plt.imshow(out_imgs[i])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnjp_IpHF5Hn",
        "colab_type": "text"
      },
      "source": [
        "# Video\n",
        "\n",
        "Now is the time to run on a video. Import the video_0 file and run it in Paris!\n",
        "If you have GPU, it's even better.\n",
        "Otherwise, use a subclip function to run it only on the first seconds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjA7cW8p0gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "video_file = \"/content/drive/My Drive/SDC Course/Tracking/Images/video_0.MOV\"\n",
        "clip = VideoFileClip(video_file).subclip(0,10)\n",
        "white_clip = clip.fl_image(main)\n",
        "%time white_clip.write_videofile(\"/content/drive/My Drive/SDC Course/Tracking/Output/movie_track.mp4\",audio=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okqy6ruRGFN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "video = io.open('/content/drive/My Drive/SDC Course/Tracking/Output/movie_track.mp4', 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<video alt=\"test\" controls width=\"320\" height=\"240\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW9EDm3wHbK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}